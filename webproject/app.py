import ast
import base64
from collections import defaultdict
import json
import logging
import os
import pickle
import ssl
import time
import traceback
import uuid
from datetime import datetime
from io import BytesIO
from threading import Lock
import requests
import pytubefix.request
import yt_dlp
from PIL import Image
from pytube import YouTube
from werkzeug.utils import secure_filename
from flask import Flask, flash, redirect, render_template, request, session, url_for, jsonify
from dotenv import load_dotenv
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import psycopg2
from psycopg2 import sql
from psycopg2.extras import RealDictCursor
import concurrent.futures
from PIL import Image, ExifTags

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ê¸°ë³¸ í™˜ê²½ ì„¤ì •
PICKLE_FILENAME = "temp_result.pkl"

# ë¡œì»¬ ì—…ë¡œë“œ í´ë” ì„¤ì •
UPLOAD_FOLDER = 'static/uploads'
if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

# ë³´ì•ˆ ë° ì¸ì¦ ê´€ë ¨ ì„¤ì •
ssl._create_default_https_context = ssl._create_unverified_context

# Youtube API ì„¤ì •
YOUTUBE_API_KEY = youtubeAPI

YOUTUBE_CREDENTIALS_PATH = 'credentials.json'
YOUTUBE_CLIENT_SECRETS_PATH = 'client_secrets.json'
youtube_service = None
youtube_lock = Lock()

# Databricks ì„¤ì •
DATABRICKS_HOST = ""
DATABRICKS_TOKEN = ""
DATABRICKS_JOB_ID = 

# í—ˆìš© ì´ë¯¸ì§€ í™•ì¥ì
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'bmp'}

# ì¥ë¥´ ëª©ë¡
genres = ["ê°€ìš”", "ë°œë¼ë“œ", "ëŒ„ìŠ¤", "ë½/ë©”íƒˆ", "POP", "ë©/í™í•©", "ì¼ë ‰íŠ¸ë¡œë‹ˆì¹´", "ì¸ë””",
    "ë¸”ë£¨ìŠ¤/í¬í¬", "íŠ¸ë¡¯", "OST", "JPOP", "ì¬ì¦ˆ", "í´ë˜ì‹", "ë‰´ì—ì´ì§€", "ì›”ë“œë®¤ì§"]

# Flask ì´ˆê¸°í™”
app = Flask(__name__)
app.secret_key = os.urandom(24)

# í™˜ê²½ ë³€ìˆ˜(.env íŒŒì¼) ë¡œë“œ 
load_dotenv()

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•¨ìˆ˜
def get_db_connection():
    try:
        conn = psycopg2.connect(
            host = os.getenv('DB_HOST'),
            port = os.getenv('DB_PORT'),
            dbname = os.getenv('DB_NAME'),
            user = os.getenv('DB_USER'),
            password = os.getenv('DB_PASSWORD'),
            options = '-c timezone=Asia/Seoul')
        conn.autocommit = True
        return conn
    except psycopg2.Error as e:
        logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def insert_image_data(web_file_path):  # âœ… ì›¹ ê²½ë¡œë§Œ ë°›ìŒ
    """ì´ë¯¸ì§€ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì‚½ì…í•˜ê³  ID ë°˜í™˜"""
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            cur.execute("""
                INSERT INTO images (file_name, upload_time)
                VALUES (%s, %s)
                RETURNING id
            """, (web_file_path, datetime.now()))  # âœ… ì›¹ ê²½ë¡œ ì €ì¥
            
            image_id = cur.fetchone()[0]
            conn.commit()
            logger.info(f"ì´ë¯¸ì§€ ë°ì´í„° ì‚½ì… ì™„ë£Œ: ID={image_id}")
            return image_id
            
    except Exception as e:
        conn.rollback()
        logger.error(f"ì´ë¯¸ì§€ ë°ì´í„° ì‚½ì… ì‹¤íŒ¨: {e}")
        raise
    finally:
        conn.close()
        
def extract_single_tag_value(tag_value):
    """íƒœê·¸ ê°’ì—ì„œ ì²« ë²ˆì§¸ ê°’ë§Œ ì¶”ì¶œ (ì´ë¯¸ì§€ëŠ” ë‹¨ì¼ íƒœê·¸)"""
    if not tag_value:
        return ''
    
    if isinstance(tag_value, list):
        return tag_value[0] if tag_value else ''
    
    if isinstance(tag_value, str):
        try:
            # "['ë“œë¼ì´ë¸Œ', 'ê±°ë¦¬']" í˜•íƒœë©´ ì²« ë²ˆì§¸ ê°’ë§Œ ì¶”ì¶œ
            parsed = ast.literal_eval(tag_value)
            if isinstance(parsed, list):
                return parsed[0] if parsed else ''
            else:
                return str(parsed)
        except:
            # íŒŒì‹± ì‹¤íŒ¨ì‹œ ì›ë³¸ ë¬¸ìì—´ ë°˜í™˜
            return tag_value.strip()
    
    return str(tag_value)

def insert_image_tags(image_id, tags_data):
    """ì´ë¯¸ì§€ íƒœê·¸ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì‚½ì… (ë‹¨ì¼ TEXT ê°’ìœ¼ë¡œ)"""
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            cur.execute("""
                INSERT INTO image_tags (image_id, tag_situation, tag_emotion, tag_time, tag_style, tag_weather, tag_season)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
            """, (
                image_id,
                extract_single_tag_value(tags_data.get('ìƒí™©', '')),
                extract_single_tag_value(tags_data.get('ê°ì„±', '')),
                extract_single_tag_value(tags_data.get('ì‹œê°„ëŒ€', '')),
                extract_single_tag_value(tags_data.get('ìŠ¤íƒ€ì¼', '')),
                extract_single_tag_value(tags_data.get('ë‚ ì”¨', '')),
                extract_single_tag_value(tags_data.get('ê³„ì ˆ', ''))
            ))
            
            conn.commit()
            logger.info(f"ì´ë¯¸ì§€ íƒœê·¸ ì‚½ì… ì™„ë£Œ: image_id={image_id}")
            
    except Exception as e:
        conn.rollback()
        logger.error(f"ì´ë¯¸ì§€ íƒœê·¸ ì‚½ì… ì‹¤íŒ¨: {e}")
        raise
    finally:
        conn.close()

def parse_tag_array(tag_value):
    """íƒœê·¸ ë¬¸ìì—´ì„ ë°°ì—´ë¡œ íŒŒì‹±"""
    if not tag_value:
        return []
    
    if isinstance(tag_value, list):
        return tag_value
    
    if isinstance(tag_value, str):
        try:
            # "['ë“œë¼ì´ë¸Œ', 'ê±°ë¦¬']" í˜•íƒœ íŒŒì‹±
            parsed = ast.literal_eval(tag_value)
            return parsed if isinstance(parsed, list) else [str(parsed)]
        except:
            # íŒŒì‹± ì‹¤íŒ¨ì‹œ ì‰¼í‘œë¡œ ë¶„í• 
            return [tag.strip() for tag in tag_value.split(',') if tag.strip()]
    
    return []

def insert_recommendations(image_id, recommendations_data):
    """ì¶”ì²œ ìŒì•… ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì‚½ì…"""
    conn = get_db_connection()
    try:
        with conn.cursor() as cur:
            for rank, song in enumerate(recommendations_data, 1):
                # íƒœê·¸ ë°ì´í„° íŒŒì‹±
                ìƒí™©íƒœê·¸ = parse_tag_array(song.get('ìƒí™©íƒœê·¸', []))
                ê°ì„±íƒœê·¸ = parse_tag_array(song.get('ê°ì„±íƒœê·¸', []))
                ì‹œê°„ëŒ€íƒœê·¸ = parse_tag_array(song.get('ì‹œê°„ëŒ€íƒœê·¸', []))
                ìŠ¤íƒ€ì¼íƒœê·¸ = parse_tag_array(song.get('ìŠ¤íƒ€ì¼íƒœê·¸', []))
                ë‚ ì”¨íƒœê·¸ = parse_tag_array(song.get('ë‚ ì”¨íƒœê·¸', []))
                ê³„ì ˆíƒœê·¸ = parse_tag_array(song.get('ê³„ì ˆíƒœê·¸', []))

                similarity_value = song.get('similarity') or song.get('ìœ ì‚¬ë„', 0.0)
                if similarity_value is None:
                    similarity_value = 0.0
                
                cur.execute("""
                    INSERT INTO recommendations (
                        image_id, rank, title, artist, genre, similarity,
                        tag_situation, tag_emotion, tag_time, tag_style, tag_weather, tag_season
                    )
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    image_id,
                    rank,
                    song.get('ê³¡ëª…', ''),
                    song.get('ê°€ìˆ˜', ''),
                    song.get('ì¥ë¥´', ''),
                    float(similarity_value),
                    ìƒí™©íƒœê·¸,
                    ê°ì„±íƒœê·¸,
                    ì‹œê°„ëŒ€íƒœê·¸,
                    ìŠ¤íƒ€ì¼íƒœê·¸,
                    ë‚ ì”¨íƒœê·¸,
                    ê³„ì ˆíƒœê·¸
                ))
            
            conn.commit()
            logger.info(f"ì¶”ì²œ ìŒì•… ë°ì´í„° ì‚½ì… ì™„ë£Œ: image_id={image_id}, ê³¡ ìˆ˜={len(recommendations_data)}")
            
    except Exception as e:
        conn.rollback()
        logger.error(f"ì¶”ì²œ ìŒì•… ë°ì´í„° ì‚½ì… ì‹¤íŒ¨: {e}")
        raise
    finally:
        conn.close()

# âœ… ìƒˆë¡œìš´ ë¡œì»¬ ì´ë¯¸ì§€ ì €ì¥ í•¨ìˆ˜
def save_image_locally(file_bytes, original_filename):
    try:
        processed_bytes = validate_and_process_image(file_bytes)
        unique_filename = f"img_{uuid.uuid4().hex}_{secure_filename(original_filename)}"
        if not unique_filename.lower().endswith('.jpg'):
            unique_filename = unique_filename.rsplit('.', 1)[0] + '.jpg'

        # ë¡œì»¬ ì €ì¥ ê²½ë¡œ (íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ì¤€)
        local_file_path = os.path.join(UPLOAD_FOLDER, unique_filename)

        with open(local_file_path, 'wb') as f:
            f.write(processed_bytes)

        logger.info(f"ë¡œì»¬ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {local_file_path}")

        # âœ… ìˆ˜ì •: DBì—ëŠ” ì›¹ ì ‘ê·¼ ê°€ëŠ¥í•œ ê²½ë¡œë§Œ ì €ì¥
        web_path = f"/static/uploads/{unique_filename}"

        return local_file_path, web_path, unique_filename  # âœ… unique_filenameë„ ë°˜í™˜
    
    except Exception as e:
        logger.error(f"ë¡œì»¬ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        raise Exception(f"ë¡œì»¬ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

def save_databricks_result_to_db(web_file_path, databricks_result):  # âœ… ì›¹ ê²½ë¡œ ë°›ìŒ
    """Databricks ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    try:
        # 1. ì´ë¯¸ì§€ ì •ë³´ ì‚½ì… (ì›¹ ê²½ë¡œ ì €ì¥)
        image_id = insert_image_data(web_file_path)  # âœ… ì›¹ ê²½ë¡œ ì „ë‹¬
        
        # 2. ì´ë¯¸ì§€ íƒœê·¸ ì‚½ì…
        if 'tags' in databricks_result:
            insert_image_tags(image_id, databricks_result['tags'])
        
        # 3. ì¶”ì²œ ìŒì•… ì‚½ì…
        if 'recommendations' in databricks_result:
            insert_recommendations(image_id, databricks_result['recommendations'])
        
        logger.info(f"Databricks ê²°ê³¼ DB ì €ì¥ ì™„ë£Œ: image_id={image_id}, web_path={web_file_path}")
        return image_id
        
    except Exception as e:
        logger.error(f"Databricks ê²°ê³¼ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        raise

def get_recommendations_by_image_id(image_id):
    """ì´ë¯¸ì§€ IDë¡œ ì¶”ì²œ ìŒì•… ì¡°íšŒ"""
    conn = get_db_connection()
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT r.*, i.file_name, i.upload_time, t.*
                FROM recommendations r
                JOIN images i ON r.image_id = i.id
                LEFT JOIN image_tags t ON r.image_id = t.image_id
                WHERE r.image_id = %s
                ORDER BY r.rank
            """, (image_id,))
            
            results = cur.fetchall()

            if results:
                print(f"ğŸ” DB ì¡°íšŒ ê²°ê³¼ ì²« ë²ˆì§¸ ë ˆì½”ë“œ:")
                print(f"   íƒ€ì…: {type(results[0])}")
                print(f"   í‚¤ë“¤: {list(results[0].keys()) if hasattr(results[0], 'keys') else 'keys() ì—†ìŒ'}")
                print(f"   ë‚´ìš©: {dict(results[0])}")

            return [dict(row) for row in results]
            
    except Exception as e:
        logger.error(f"ì¶”ì²œ ìŒì•… ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise
    finally:
        conn.close()

def get_recent_recommendations(limit=10):
    """ìµœê·¼ ì¶”ì²œ ìŒì•… ì¡°íšŒ"""
    conn = get_db_connection()
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT DISTINCT ON (r.image_id) r.image_id, i.file_name, i.upload_time,
                       COUNT(r.id) as recommendation_count
                FROM recommendations r
                JOIN images i ON r.image_id = i.id
                GROUP BY r.image_id, i.file_name, i.upload_time
                ORDER BY i.upload_time DESC
                LIMIT %s
            """, (limit,))
            
            results = cur.fetchall()
            return [dict(row) for row in results]
            
    except Exception as e:
        logger.error(f"ìµœê·¼ ì¶”ì²œ ìŒì•… ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise
    finally:
        conn.close()

def is_audio_url_playable(audio_url, timeout=5):
    try:
        headers = {
            "Range": "bytes=0-65535"
        }
        resp = requests.get(audio_url, headers=headers, timeout=timeout, stream=True)
        if resp.status_code in (200, 206) and resp.headers.get("Content-Type", "").startswith("audio"):
            return True
    except Exception as e:
        print(f"ì˜¤ë””ì˜¤ url ì¬ìƒ ë¶ˆê°€: {e}")
    return False

def save_result_pickle(result, filename=PICKLE_FILENAME):
    """ì¶”ì²œ ê²°ê³¼ë¥¼ pickle íŒŒì¼ë¡œ ì €ì¥"""
    with open(filename, "wb") as f:
        pickle.dump(result, f)

def load_result_pickle(filename=PICKLE_FILENAME):
    """pickle íŒŒì¼ì—ì„œ ì¶”ì²œ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°"""
    if os.path.exists(filename):
        with open(filename, "rb") as f:
            return pickle.load(f)
    return None

def search_youtube_video_url_list(query, max_results=5):
    """ê²€ìƒ‰ì–´ë¡œ ìœ íŠœë¸Œ ì˜ìƒ URL ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    try:
        youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)
        request = youtube.search().list(
            q=query,
            part="snippet",
            type="video",
            maxResults=max_results
        )
        response = request.execute()
        video_data = []
        for item in response["items"]:
            # videoId ì—†ëŠ” ê²½ìš° ë¬´ì‹œ (KeyError ë°©ì§€)
            if "videoId" not in item["id"]:
                continue
            video_data.append({
                "title": item["snippet"]["title"],
                "channel": item["snippet"]["channelTitle"],
                "url": f"https://www.youtube.com/watch?v={item['id']['videoId']}"
            })
        # Topic ì±„ë„ > Official/MV > ë‚˜ë¨¸ì§€ ìˆœ ì •ë ¬
        sorted_data = []
        sorted_data += [v for v in video_data if v["channel"].endswith(" - Topic")]
        sorted_data += [v for v in video_data if any(k in v["title"].lower() for k in ["official", "mv", "music video"]) and v not in sorted_data]
        sorted_data += [v for v in video_data if v not in sorted_data]
        return [v["url"] for v in sorted_data]
    except Exception as e:
        print(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

def get_valid_youtube_audio_url(video_url_list):
    """
    ìœ íŠœë¸Œ ì˜ìƒ URL ë¦¬ìŠ¤íŠ¸ì—ì„œ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì„±ê³µ + ì‹¤ì œ ë¸Œë¼ìš°ì € ì¬ìƒ ê°€ëŠ¥í•œ ì²« ë²ˆì§¸ URL ë°˜í™˜
    """
    for url in video_url_list:
        try:
            ydl_opts = {
                'format': 'bestaudio/best',
                'quiet': True,
                'skip_download': True,
                'cookiefile': './cookies.txt',  # í•„ìš”ì‹œë§Œ
            }
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                audio_url = info.get('url')
                # ì‹¤ì œ audio ìŠ¤íŠ¸ë¦¼ì´ ì¬ìƒ ê°€ëŠ¥í•œì§€ ê²€ì¦
                if audio_url and is_audio_url_playable(audio_url):
                    return audio_url
        except Exception as e:
            print(f"ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            continue
    return None

def add_audio_urls_to_recommendations(recommendations, max_workers=5):
    def fetch_audio_url(song_info):
        song, index = song_info
        try:
            artist = song.get('ê°€ìˆ˜', '').strip()
            title = song.get('ê³¡ëª…', '').strip()
            if not artist or not title:
                return None
            
            search_query = f"{artist} {title}".strip()
            video_url_list = search_youtube_video_url_list(search_query, max_results=5)
            audio_url = get_valid_youtube_audio_url(video_url_list)
            
            if audio_url and test_audio_url(audio_url):
                song['audio_url'] = audio_url
                return song  # ì„±ê³µí•œ ê³¡ë§Œ ë°˜í™˜
            else:
                return None  # ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
        except Exception as e:
            return None

    song_infos = [(song, i) for i, song in enumerate(recommendations)]
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = list(executor.map(fetch_audio_url, song_infos))

    # ì‹¤íŒ¨(None)ì¸ ê³¡ì€ ì œì™¸
    valid_recommendations = [song for song in results if song is not None]
    return valid_recommendations

def test_audio_url(audio_url):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0"
        }
        r = requests.get(audio_url, headers=headers, stream=True, timeout=10)
        if r.status_code == 200 and "audio" in r.headers.get("Content-Type", ""):
            # ì‹¤ì œ ìŠ¤íŠ¸ë¦¼ ì¼ë¶€ë¥¼ ì½ì–´ì„œ ì¬ìƒ ê°€ëŠ¥ ì—¬ë¶€ ê°€ëŠ 
            next(r.iter_content(1024*64))
            return True
        else:
            return False
    except Exception as e:
        print(f"ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

# âœ… ì»¤ìŠ¤í…€ í•„í„° ì¶”ê°€
@app.template_filter('split')
def split_filter(value, delimiter=','):
    """ë¬¸ìì—´ì„ êµ¬ë¶„ìë¡œ ë¶„í• í•˜ëŠ” í•„í„°"""
    if isinstance(value, str):
        return value.split(delimiter)
    return value

@app.template_filter('parse_list')
def parse_list_filter(value):
    """ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ëŠ” í•„í„°"""
    if isinstance(value, str):
        # "['ë“œë¼ì´ë¸Œ']" í˜•íƒœë¥¼ ì²˜ë¦¬
        try:
            return ast.literal_eval(value)
        except:
            # íŒŒì‹± ì‹¤íŒ¨ì‹œ ë¬¸ìì—´ì„ ì§ì ‘ ì²˜ë¦¬
            return value.replace("[", "").replace("]", "").replace("'", "").split(", ")
    return value if isinstance(value, list) else []

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def validate_and_process_image(file_bytes):
    """ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦ ë° EXIF íšŒì „ ì²˜ë¦¬ í¬í•¨"""
    try:
        img = Image.open(BytesIO(file_bytes))

        # EXIF Orientation ì²˜ë¦¬
        try:
            exif = img._getexif()
            if exif is not None:
                for orientation in ExifTags.TAGS.keys():
                    if ExifTags.TAGS[orientation] == 'Orientation':
                        break
                orientation_value = exif.get(orientation, None)

                if orientation_value == 3:
                    img = img.rotate(180, expand=True)
                elif orientation_value == 6:
                    img = img.rotate(270, expand=True)
                elif orientation_value == 8:
                    img = img.rotate(90, expand=True)
        except Exception as e:
            print(f"EXIF íšŒì „ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

        # RGBë¡œ ë³€í™˜
        if img.mode in ('RGBA', 'LA', 'P'):
            img = img.convert('RGB')

        # í¬ê¸° ì œí•œ
        max_size = (1024, 1024)
        if img.size[0] > max_size[0] or img.size[1] > max_size[1]:
            img.thumbnail(max_size, Image.Resampling.LANCZOS)

        # ì €ì¥
        output = BytesIO()
        img.save(output, format='JPEG', quality=85)
        return output.getvalue()

    except Exception as e:
        raise ValueError(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

# âœ… ì™„ì „íˆ ìˆ˜ì •ëœ DBFSì— ì´ë¯¸ì§€ ì €ì¥ í•¨ìˆ˜
def save_file_to_dbfs(file_bytes, filename):
    try:
        # ì´ë¯¸ì§€ ê²€ì¦ ë° ì²˜ë¦¬
        processed_bytes = validate_and_process_image(file_bytes)
        
        unique_filename = f"img_{uuid.uuid4().hex}_{secure_filename(filename)}"
        # í™•ì¥ìë¥¼ .jpgë¡œ í†µì¼
        if not unique_filename.lower().endswith('.jpg'):
            unique_filename = unique_filename.rsplit('.', 1)[0] + '.jpg'
        
        dbfs_path = f"/FileStore/uploads/{unique_filename}"
        
        headers = {"Authorization": f"Bearer {DATABRICKS_TOKEN}"}
        
        # íŒŒì¼ í¬ê¸° ì²´í¬ (1MB ì´í•˜ëŠ” put API, ì´ìƒì€ create-add-close)
        if len(processed_bytes) <= 1024 * 1024:  # 1MB ì´í•˜
            # POST /api/2.0/dbfs/put ì‚¬ìš© (ê°„ë‹¨í•œ ì—…ë¡œë“œ)
            encoded_data = base64.b64encode(processed_bytes).decode('utf-8')
            
            response = requests.post(
                f"{DATABRICKS_HOST}/api/2.0/dbfs/put",
                headers=headers,
                json={
                    "path": dbfs_path,
                    "contents": encoded_data,
                    "overwrite": True
                }
            )
            
            if response.status_code != 200:
                raise Exception(f"DBFS put ì‹¤íŒ¨: {response.text}")
                
        else:  # 1MB ì´ˆê³¼ (ì²­í¬ ì—…ë¡œë“œ)
            # 1. create handle
            create_response = requests.post(
                f"{DATABRICKS_HOST}/api/2.0/dbfs/create",
                headers=headers,
                json={"path": dbfs_path, "overwrite": True}
            )
            
            if create_response.status_code != 200:
                raise Exception(f"DBFS create ì‹¤íŒ¨: {create_response.text}")
                
            handle = create_response.json()["handle"]

            try:
                # 2. add blocks
                chunk_size = 1024 * 1024  # 1MB ì²­í¬
                
                for i in range(0, len(processed_bytes), chunk_size):
                    chunk = processed_bytes[i:i + chunk_size]
                    encoded_chunk = base64.b64encode(chunk).decode('utf-8')
                    
                    add_response = requests.post(
                        f"{DATABRICKS_HOST}/api/2.0/dbfs/add-block",
                        headers=headers,
                        json={
                            "handle": handle,
                            "data": encoded_chunk
                        }
                    )
                    
                    if add_response.status_code != 200:
                        raise Exception(f"DBFS add-block ì‹¤íŒ¨: {add_response.text}")

                # 3. close handle
                close_response = requests.post(
                    f"{DATABRICKS_HOST}/api/2.0/dbfs/close",
                    headers=headers,
                    json={"handle": handle}
                )
                
                if close_response.status_code != 200:
                    raise Exception(f"DBFS close ì‹¤íŒ¨: {close_response.text}")
                    
            except Exception as e:
                # ì‹¤íŒ¨ ì‹œ handle ë‹«ê¸° ì‹œë„
                try:
                    requests.post(
                        f"{DATABRICKS_HOST}/api/2.0/dbfs/close",
                        headers=headers,
                        json={"handle": handle}
                    )
                except:
                    pass
                raise e
        
        return dbfs_path
        
    except Exception as e:
        raise Exception(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

# ë””ë²„ê¹…ìš© í•¨ìˆ˜
def test_dbfs_connection():
    """DBFS ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        headers = {"Authorization": f"Bearer {DATABRICKS_TOKEN}"}
        
        # DBFS ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì¡°íšŒ
        response = requests.get(
            f"{DATABRICKS_HOST}/api/2.0/dbfs/list",
            headers=headers,
            params={"path": "/"}
        )
        
        print(f"DBFS ì—°ê²° í…ŒìŠ¤íŠ¸ ê²°ê³¼: {response.status_code}")
        print(f"ì‘ë‹µ: {response.text}")
        
        return response.status_code == 200
        
    except Exception as e:
        print(f"DBFS ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

# âœ… ìˆ˜ì •ëœ Databricks Job ì‹¤í–‰ í•¨ìˆ˜
def run_databricks_job(image_path, selected_genres):
    payload = {
        "job_id": DATABRICKS_JOB_ID,
        "notebook_params": {
            "image_path": image_path,
            "genres": json.dumps(selected_genres)
        }
    }

    headers = {"Authorization": f"Bearer {DATABRICKS_TOKEN}"}

    response = requests.post(f"{DATABRICKS_HOST}/api/2.1/jobs/run-now", json=payload, headers=headers)
    response.raise_for_status()
    run_id = response.json()["run_id"]

    # ëŒ€ê¸°
    max_wait_time = 300  # 5ë¶„ ìµœëŒ€ ëŒ€ê¸°
    start_time = time.time()
    
    while True:
        if time.time() - start_time > max_wait_time:
            raise Exception("Job ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼")
            
        status_response = requests.get(
            f"{DATABRICKS_HOST}/api/2.1/jobs/runs/get",
            headers=headers,
            params={"run_id": run_id}
        )
        
        status_data = status_response.json()
        status = status_data["state"]["life_cycle_state"]
        
        if status in ["TERMINATED", "SKIPPED", "INTERNAL_ERROR"]:
            # ì‹¤íŒ¨í•œ ê²½ìš° ì—ëŸ¬ ì •ë³´ í¬í•¨
            if status == "INTERNAL_ERROR":
                raise Exception(f"Databricks Job ì‹¤í–‰ ì‹¤íŒ¨: {status_data}")
            break
            
        time.sleep(3)

    # âœ… ìˆ˜ì •ëœ ë¶€ë¶„: ê°œë³„ íƒœìŠ¤í¬ ê²°ê³¼ ì¡°íšŒ
    try:
        # ë¨¼ì € run ì •ë³´ë¥¼ ë‹¤ì‹œ ê°€ì ¸ì™€ì„œ tasks í™•ì¸
        run_info_response = requests.get(
            f"{DATABRICKS_HOST}/api/2.1/jobs/runs/get",
            headers=headers,
            params={"run_id": run_id}
        )
        
        if run_info_response.status_code != 200:
            raise Exception(f"Run ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {run_info_response.text}")
        
        run_info = run_info_response.json()
        
        # tasksê°€ ìˆëŠ”ì§€ í™•ì¸
        if "tasks" in run_info and run_info["tasks"]:
            # ì²« ë²ˆì§¸ íƒœìŠ¤í¬ì˜ run_id ì‚¬ìš©
            task_run_id = run_info["tasks"][0]["run_id"]
            print(f"íƒœìŠ¤í¬ run_id ì‚¬ìš©: {task_run_id}")
            
            # ê°œë³„ íƒœìŠ¤í¬ ê²°ê³¼ ì¡°íšŒ
            result_response = requests.get(
                f"{DATABRICKS_HOST}/api/2.1/jobs/runs/get-output",
                headers=headers,
                params={"run_id": task_run_id}
            )
        else:
            # ë‹¨ì¼ íƒœìŠ¤í¬ì¸ ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            print("ë‹¨ì¼ íƒœìŠ¤í¬ë¡œ ê°ì§€, ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©")
            result_response = requests.get(
                f"{DATABRICKS_HOST}/api/2.1/jobs/runs/get-output",
                headers=headers,
                params={"run_id": run_id}
            )
        
        if result_response.status_code != 200:
            raise Exception(f"ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {result_response.text}")
        
        result_data = result_response.json()
        
        # notebook_outputì´ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        if "notebook_output" not in result_data:
            raise Exception(f"ë…¸íŠ¸ë¶ ì¶œë ¥ì´ ì—†ìŠµë‹ˆë‹¤: {result_data}")
        
        result = result_data["notebook_output"].get("result", "{}")

        try:
            parsed_result = json.loads(result)
            
            # âœ… ìˆ˜ì •: error í•„ë“œì— ì‹¤ì œ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
            if "error" in parsed_result and isinstance(parsed_result["error"], str):
                try:
                    # error í•„ë“œë¥¼ JSONìœ¼ë¡œ íŒŒì‹±í•´ë³´ê¸°
                    potential_result = json.loads(parsed_result["error"])
                    if "recommendations" in potential_result and "tags" in potential_result:
                        print("âœ… error í•„ë“œì—ì„œ ì‹¤ì œ ê²°ê³¼ ë°œê²¬!")
                        return potential_result
                except json.JSONDecodeError:
                    # error í•„ë“œê°€ JSONì´ ì•„ë‹ˆë©´ ì‹¤ì œ ì—ëŸ¬ë¡œ ì²˜ë¦¬
                    raise Exception(f"Databricks ì²˜ë¦¬ ì—ëŸ¬: {parsed_result['error']}")

            # ì •ìƒì ì¸ ê²°ê³¼ í™•ì¸
            if "recommendations" in parsed_result and "tags" in parsed_result:
                return parsed_result
            
            # ê·¸ ì™¸ì˜ ê²½ìš°ëŠ” ì—ëŸ¬ë¡œ ì²˜ë¦¬
            raise Exception(f"ì˜ˆìƒí•˜ì§€ ëª»í•œ ê²°ê³¼ í˜•ì‹: {parsed_result}")
            
        except json.JSONDecodeError:
            raise Exception(f"ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨: {result}")
            
    except Exception as e:
        print(f"ê²°ê³¼ ì¡°íšŒ ì¤‘ ì—ëŸ¬: {str(e)}")
        raise

# ì¶”ì²œ ê²°ê³¼ ì „ì²˜ë¦¬ í•¨ìˆ˜
def process_recommendation_result(result):
    """ì¶”ì²œ ê²°ê³¼ë¥¼ í…œí”Œë¦¿ì—ì„œ ì‚¬ìš©í•˜ê¸° ì‰½ê²Œ ì „ì²˜ë¦¬ + YouTube ì˜¤ë””ì˜¤ URL ì¶”ê°€"""
    try:
        if 'recommendations' in result:
            # ê¸°ì¡´ íƒœê·¸ ì „ì²˜ë¦¬
            for song in result['recommendations']:
                print(f"ê³¡ëª…: {song.get('ê³¡ëª…')}, ì˜¤ë””ì˜¤ URL: {song.get('audio_url')}")
                tag_fields = ['ìƒí™©íƒœê·¸', 'ê°ì„±íƒœê·¸', 'ì‹œê°„ëŒ€íƒœê·¸', 'ìŠ¤íƒ€ì¼íƒœê·¸', 'ë‚ ì”¨íƒœê·¸', 'ê³„ì ˆíƒœê·¸']
                
                for field in tag_fields:
                    if field in song:
                        tag_value = song[field]
                        if isinstance(tag_value, str):
                            try:
                                parsed_tags = ast.literal_eval(tag_value)
                                song[f'parsed_{field}'] = parsed_tags if isinstance(parsed_tags, list) else []
                            except:
                                song[f'parsed_{field}'] = []
                        else:
                            song[f'parsed_{field}'] = tag_value if isinstance(tag_value, list) else []
            
            # âœ… ìˆ˜ì •ëœ YouTube ì˜¤ë””ì˜¤ URL ì¶”ê°€ (ìˆœì„œ ë³´ì¡´)
            print("ğŸµ YouTube ì˜¤ë””ì˜¤ URL ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            result['recommendations'] = add_audio_urls_to_recommendations(
                result['recommendations'], 
                max_workers=3  # ë„ˆë¬´ ë§ì€ ë™ì‹œ ìš”ì²­ ë°©ì§€
            )
            
            # í†µê³„ ì¶œë ¥
            total_songs = len(result['recommendations'])
            playable_songs = sum(1 for song in result['recommendations'] if song.get('has_audio', False))
            print(f"âœ… YouTube ì˜¤ë””ì˜¤ URL ì¶”ê°€ ì™„ë£Œ: {playable_songs}/{total_songs}ê³¡ ì¬ìƒ ê°€ëŠ¥")
            print(result)
        return result
    except Exception as e:
        print(f"ê²°ê³¼ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        return result

def convert_db_to_template_format(db_recommendations):
    """DBì—ì„œ ê°€ì ¸ì˜¨ ì¶”ì²œ ë°ì´í„°ë¥¼ í…œí”Œë¦¿ì—ì„œ ì‚¬ìš©í•  í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not db_recommendations:
        return None
    
    # ì²« ë²ˆì§¸ ë ˆì½”ë“œì—ì„œ ì´ë¯¸ì§€ ì •ë³´ì™€ íƒœê·¸ ì¶”ì¶œ
    first_record = db_recommendations[0]
    tag_fields_mapping = {
        'ìƒí™©': 'tag_situation',
        'ê°ì„±': 'tag_emotion', 
        'ì‹œê°„ëŒ€': 'tag_time',
        'ìŠ¤íƒ€ì¼': 'tag_style',
        'ë‚ ì”¨': 'tag_weather',
        'ê³„ì ˆ': 'tag_season'
    }
    
    # íƒœê·¸ ì •ë³´ êµ¬ì„±
    tags = {}
    for kr_field, db_field in tag_fields_mapping.items():
        if db_field in first_record and first_record[db_field]:
            tags[kr_field] = first_record[db_field]
    
    # ì¶”ì²œ ìŒì•… ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
    recommendations = []
    for record in db_recommendations:
        similarity_score = float(record.get('similarity', 0.0) if record.get('similarity') is not None else 0.0)

        song = {
            'ê³¡ëª…': record.get('title', ''),
            'ê°€ìˆ˜': record.get('artist', ''),
            'ì¥ë¥´': record.get('genre', ''),
            'similarity': similarity_score, 
            'ìœ ì‚¬ë„': similarity_score,
            'audio_url': None
        }
    
        # íƒœê·¸ ì •ë³´ ì¶”ê°€
        tag_fields_mapping_song = {
            'ìƒí™©íƒœê·¸': 'tag_situation',
            'ê°ì„±íƒœê·¸': 'tag_emotion',
            'ì‹œê°„ëŒ€íƒœê·¸': 'tag_time',
            'ìŠ¤íƒ€ì¼íƒœê·¸': 'tag_style',
            'ë‚ ì”¨íƒœê·¸': 'tag_weather',
            'ê³„ì ˆíƒœê·¸': 'tag_season'
        }
        
        for kr_field, db_field in tag_fields_mapping_song.items():
            if db_field in record and record[db_field]:
                song[kr_field] = record[db_field]
                song[f'parsed_{kr_field}'] = parse_tag_array(record[db_field])
        recommendations.append(song)
    
    # YouTube ì˜¤ë””ì˜¤ URL ì¶”ê°€
    recommendations = add_audio_urls_to_recommendations(recommendations)
    
    # âœ… ìˆ˜ì •ëœ ì´ë¯¸ì§€ ê²½ë¡œ ì²˜ë¦¬
    db_path = first_record.get('file_name', '')  # DBì—ì„œ ì›¹ ê²½ë¡œ ê°€ì ¸ì˜´
    
    # DB ê²½ë¡œì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
    if db_path.startswith('/static/uploads/'):
        filename = db_path.replace('/static/uploads/', '')
    elif db_path.startswith('static/uploads/'):
        filename = db_path.replace('static/uploads/', '')
    elif db_path.startswith('uploads/'):
        filename = db_path.replace('uploads/', '')
    else:
        filename = db_path
    
    result = {
        'tags': tags,
        'recommendations': recommendations,
        'image_info': {
            'filename': f'uploads/{filename}',  # âœ… url_forìš© ê²½ë¡œ (static/ ì œì™¸)
            'upload_time': first_record.get('upload_time', ''),
            'image_id': first_record.get('image_id', ''),
            'web_url': f'/static/uploads/{filename}',  # âœ… ì§ì ‘ ì ‘ê·¼ìš© ê²½ë¡œ
            'static_filename': f'uploads/{filename}'  # âœ… ìƒˆë¡œ ì¶”ê°€: url_forìš©
        }
    }
    return result

# âœ… ë©”ì¸ í˜ì´ì§€
@app.route('/home/', methods=['GET', 'POST'])
def home():
    error = None
    if request.method == 'POST':
        try:
            file = request.files.get('image')
            selected_genres_str = request.form.get('selected_genres')
            selected_genres = selected_genres_str.split(",") if selected_genres_str else []

            if not file or file.filename == '':
                error = "ì´ë¯¸ì§€ íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                return render_template('home.html', genres=genres, error=error)

            if not allowed_file(file.filename):
                error = "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."
                return render_template('home.html', genres=genres, error=error)

            if not selected_genres:
                error = "ìµœì†Œ 1ê°œì˜ ì¥ë¥´ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."
                return render_template('home.html', genres=genres, error=error)

            image_bytes = file.read()

            # âœ… ìˆ˜ì •ëœ ë¶€ë¶„
            local_path, web_path, unique_filename = save_image_locally(image_bytes, file.filename)

            session['local_file_path'] = local_path
            session['image_web_path'] = web_path  # âœ… ì›¹ ê²½ë¡œ ì €ì¥
            session['unique_filename'] = unique_filename  # âœ… íŒŒì¼ëª…ë§Œ ì €ì¥
            session['filename'] = file.filename
            session['selected_genres'] = selected_genres

            return redirect(url_for('loading'))

        except Exception as e:
            traceback.print_exc()
            error = f"ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}"

    return render_template('home.html', genres=genres, error=error)

@app.route('/loading')
def loading():
    return render_template('loading.html')

@app.route('/process_recommendation')
def process_recommendation():
    try:
        local_file_path = session.get('local_file_path')
        web_path = session.get('image_web_path')  # âœ… ì›¹ ê²½ë¡œ ì‚¬ìš©
        filename = session.get('filename')
        selected_genres = session.get('selected_genres')

        if not local_file_path or not web_path or not filename or not selected_genres:
            return jsonify({'success': False, 'message': 'ì„¸ì…˜ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.'})

        with open(local_file_path, 'rb') as f:
            image_bytes = f.read()

        dbfs_path = save_file_to_dbfs(image_bytes, filename)
        result = run_databricks_job(dbfs_path, selected_genres)
        processed_result = process_recommendation_result(result)
        
        # âœ… ì›¹ ê²½ë¡œë¥¼ DBì— ì €ì¥
        image_id = save_databricks_result_to_db(web_path, processed_result)
        save_result_pickle(processed_result)

        session['current_image_id'] = image_id
        session['current_image_path'] = local_file_path

        return jsonify({'success': True})

    except Exception as e:
        traceback.print_exc()
        return jsonify({'success': False, 'message': str(e)})

@app.route('/recommendation/', methods=['GET'])
def recommendation():
    try:
        # URL íŒŒë¼ë¯¸í„°ë¡œ image_idê°€ ì „ë‹¬ëœ ê²½ìš°
        image_id = request.args.get('image_id')
        
        if image_id:
            # DBì—ì„œ íŠ¹ì • ì´ë¯¸ì§€ì˜ ì¶”ì²œ ê²°ê³¼ ì¡°íšŒ
            recommendations = get_recommendations_by_image_id(image_id)
            if recommendations:
                # DB ë°ì´í„°ë¥¼ í…œí”Œë¦¿ìš©ìœ¼ë¡œ ë³€í™˜
                result = convert_db_to_template_format(recommendations)
                
                logger.debug(f"í…œí”Œë¦¿ì— ì „ë‹¬ë˜ëŠ” result êµ¬ì¡°: {result}")
                return render_template('view.html', result=result, image_id=image_id)
        
        # ì„¸ì…˜ì—ì„œ í˜„ì¬ ì´ë¯¸ì§€ ID í™•ì¸
        current_image_id = session.get('current_image_id')
        if current_image_id:
            recommendations = get_recommendations_by_image_id(current_image_id)
            if recommendations:
                result = convert_db_to_template_format(recommendations)
                return render_template('view.html', result=result, image_id=current_image_id)
        
        # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ pickleì—ì„œ ê°€ì ¸ì˜¤ê¸° (ê¸°ì¡´ ë°©ì‹)
        result = load_result_pickle()
        
        # âœ… pickle ê²°ê³¼ì—ë„ ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ê°€ (ì„¸ì…˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        if result and session.get('image_web_path'):
            if 'image_info' not in result:
                result['image_info'] = {}
            
            # ì„¸ì…˜ì—ì„œ ê°€ì ¸ì˜¨ ì›¹ ê²½ë¡œ ì²˜ë¦¬
            web_path = session.get('image_web_path')  # /static/uploads/filename.jpg
            if web_path.startswith('/static/uploads/'):
                filename = web_path.replace('/static/uploads/', '')
            elif web_path.startswith('static/uploads/'):
                filename = web_path.replace('static/uploads/', '')
            else:
                filename = web_path
            
            result['image_info']['web_url'] = f'/static/uploads/{filename}'
            result['image_info']['static_filename'] = f'uploads/{filename}'  # âœ… url_forìš©
        
        return render_template('view.html', result=result)
        
    except Exception as e:
        logger.error(f"í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        flash("í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "error")
        return redirect(url_for('home'))

# ì´ë¯¸ì§€ íŒŒì¼ê³¼ image_id ë§¤í•‘
def get_image_mapping():
    conn = get_db_connection()
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute("""
                SELECT id, file_name
                FROM images
                ORDER BY upload_time DESC
                LIMIT 20
            """)
            results = cur.fetchall()
            return {r['file_name']: r['id'] for r in results}
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ë§¤í•‘ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {}
    finally:
        conn.close()

def fetch_archive_photos(limit: int | None = None):
    conn = get_db_connection()
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(f"""
                SELECT i.id AS image_id,
                       i.file_name,
                       p.rank,
                       p.title,
                       p.artist,
                       COALESCE(p.genre, '') AS genre,
                       p.tag_situation,
                       p.tag_emotion,
                       p.tag_time,
                       p.tag_style,
                       p.tag_weather,
                       p.tag_season
                FROM images i
                LEFT JOIN recommendations p ON p.image_id = i.id
                ORDER BY i.upload_time DESC, p.rank
                {'' if not limit else 'LIMIT %s'}
            """, (limit,) if limit else ())
            rows = cur.fetchall()
 
        photo_dict = defaultdict(lambda: {"file_name": "", "songs": [], "tags": set()})
 
        for r in rows:
            pid = r["image_id"]
            photo_dict[pid]["file_name"] = r["file_name"]
 
            # ì¶”ì²œê³¡ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            if r["title"]:  # playlistì— ê³¡ì´ ì¡´ì¬
                photo_dict[pid]["songs"].append({
                    "title":  r["title"],
                    "artist": r["artist"],
                    "genre":  r["genre"]
                })
 
            # íƒœê·¸ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            tag_cols = ["tag_situation", "tag_emotion", "tag_time",
                        "tag_style", "tag_weather", "tag_season"]
            for col in tag_cols:
                tag_values = r.get(col)
                if tag_values:  # TEXT[]
                    photo_dict[pid]["tags"].update(tag_values)
 
        # set â†’ list ë³€í™˜ & dict â†’ list ë³€í™˜
        photos = []
        for pid, info in photo_dict.items():
            info["tags"] = list(info["tags"])
            photos.append(info) 
        return photos
 
    except Exception as e:
        logger.error(f"ì•„ì¹´ì´ë¸Œ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []
    finally:
        conn.close()
 
@app.route('/archive/')
def archive():
    try:
        photos = fetch_archive_photos()
        image_mapping = get_image_mapping()  # ì´ë¯¸ì§€ ID ë§¤í•‘ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        
        for photo in photos:
            fname = photo['file_name']
            
            # âœ… DBì— ì €ì¥ëœ ê²½ë¡œ í˜•ì‹ í™•ì¸ ë° ì •ê·œí™”
            if fname.startswith('/static/uploads/'):
                # '/static/uploads/filename.jpg' í˜•íƒœ
                clean_filename = fname.replace('/static/uploads/', '')
            elif fname.startswith('static/uploads/'):
                # 'static/uploads/filename.jpg' í˜•íƒœ  
                clean_filename = fname.replace('static/uploads/', '')
            elif fname.startswith('/uploads/'):
                # '/uploads/filename.jpg' í˜•íƒœ
                clean_filename = fname.replace('/uploads/', '')
            elif fname.startswith('uploads/'):
                # 'uploads/filename.jpg' í˜•íƒœ
                clean_filename = fname.replace('uploads/', '')
            else:
                # 'filename.jpg' í˜•íƒœ (ìˆœìˆ˜ íŒŒì¼ëª…)
                clean_filename = fname
            
            # âœ… ì›¹ ì ‘ê·¼ ê°€ëŠ¥í•œ URL ìƒì„±
            photo["file_url"] = f"/static/uploads/{clean_filename}"
            
            # âœ… ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶”ê°€
            logger.info(f"Archive ì´ë¯¸ì§€ ê²½ë¡œ: DB={fname} -> URL={photo['file_url']}")
            
            # âœ… ì´ë¯¸ì§€ ID ì¶”ê°€ (view í˜ì´ì§€ ì—°ê²°ìš©)
            photo["image_id"] = image_mapping.get(fname, None)

        return render_template('archive.html', photos=photos)
    
    except Exception as e:
        logger.error(f"ì•„ì¹´ì´ë¸Œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        flash("ì•„ì¹´ì´ë¸Œë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", "error")
        return render_template('archive.html', photos=[])
    
@app.route('/api/recommendations/<int:image_id>')
def get_recommendations_api(image_id):
    """íŠ¹ì • ì´ë¯¸ì§€ì˜ ì¶”ì²œ ìŒì•…ì„ JSONìœ¼ë¡œ ë°˜í™˜"""
    try:
        recommendations = get_recommendations_by_image_id(image_id)
        if not recommendations:
            return {"error": "ì¶”ì²œ ìŒì•…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}, 404
        
        result = convert_db_to_template_format(recommendations)
        return result
    except Exception as e:
        logger.error(f"API ì¶”ì²œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"error": "ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}, 500
    
def handle_database_error(error_msg, redirect_route='home'):
    """ë°ì´í„°ë² ì´ìŠ¤ ì—ëŸ¬ ê³µí†µ ì²˜ë¦¬"""
    logger.error(error_msg)
    flash("ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", "error")
    return redirect(url_for(redirect_route))

# ì„¸ì…˜ ì •ë¦¬ í•¨ìˆ˜
@app.route('/clear-session')
def clear_session():
    """ì„¸ì…˜ ì •ë¦¬ (ë””ë²„ê¹…ìš©)"""
    session.clear()
    return redirect(url_for('home'))

# âœ… ë£¨íŠ¸ ê²½ë¡œ
@app.route('/')
def index():
    return render_template('home.html', genres=genres, error=None)

if __name__ == '__main__':
    # DBFS ì—°ê²° í…ŒìŠ¤íŠ¸ (ì„ íƒì )
    print("ğŸ”„ DBFS ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
    if test_dbfs_connection():
        print("âœ… DBFS ì—°ê²° ì„±ê³µ")
    else:
        print("âŒ DBFS ì—°ê²° ì‹¤íŒ¨ - í† í°ì´ë‚˜ í˜¸ìŠ¤íŠ¸ í™•ì¸ í•„ìš”")
        print("âš ï¸  ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹œì‘í•˜ì§€ë§Œ íŒŒì¼ ì—…ë¡œë“œê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    print("ğŸš€ Flask ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘...")
    app.run(host='0.0.0.0', port=5000, debug=True)
